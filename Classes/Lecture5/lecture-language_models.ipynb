{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1727118633692,
     "user": {
      "displayName": "Andrew Zachary",
      "userId": "08217951406983746510"
     },
     "user_tz": 240
    },
    "id": "4_utP1oeR5MP",
    "outputId": "64774304-ad98-4921-8f3e-0084d9620bf9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font = {'size': 16}\n",
    "# matplotlib.rc('font', **font)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXBHldZdR5MR"
   },
   "source": [
    "### until now: 'bag of words assumption', but text has structure!\n",
    "\n",
    "\n",
    "# Language Models I\n",
    "\n",
    "- ### Text contains a lot of information\n",
    "    - ### Find a way to model it (word counts, syntactics, semantics, etc)\n",
    "    - ### Use huge amounts of text\n",
    "\n",
    "- ### Gray area between unsupervised <-> supervised\n",
    "\n",
    "- ### These are the building blocks for algorithms like GPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQv9ZlVAR5MT"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1SizxaFR5MT"
   },
   "source": [
    "# Common Tasks for a Language Model\n",
    "## 1) Associate a probability with text\n",
    "- ### eg P(real sentence) vs P(not a real sentence)\n",
    "\n",
    "## 2) For a given text predict the next word (GPT) - can we predict the 'future'?\n",
    "- ### eg \"It's raining today so i should bring an `<?>`\"\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Questions\n",
    "- ### Why is this enough for gpt?\n",
    "- ### What's the limit? (causality)\n",
    "- ### Is this (un)supervised? (this gray area will become even blurrier once we learn about neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djCQwRrJR5MT"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkNnnIfAR5MU"
   },
   "source": [
    "# Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--pYLp-5R5MU"
   },
   "source": [
    "# Translation: German -> English\n",
    "\n",
    "## \"Gestern habe ich beim MIT einen burger gegessen.\"\n",
    "## \"Hier, j'ai mang√© un hamburger au MIT\"\n",
    "\n",
    "##\n",
    "\n",
    "##\n",
    "\n",
    ">### Yesterday have I at MIT a burger eaten.\n",
    ">### <small>(Score 21%)</small>\n",
    "\n",
    "## vs\n",
    "\n",
    ">### Yesterday I ate an MIT at a burger.\n",
    ">### <small>(Score 65%)</small>\n",
    "\n",
    "## vs\n",
    "\n",
    ">### Yesterday I ate a burger at MIT.\n",
    ">### <small>(Score 92%)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5yISVTvR5MV"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhgI62V7R5MV"
   },
   "source": [
    "# Speech Recognition:\n",
    "\n",
    ">### How to wreck a nice beach\n",
    "\n",
    "## vs\n",
    "\n",
    ">### How to recognize speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7P2WiB-cR5MW"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KGlL30UR5MW"
   },
   "source": [
    "# Search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajqERxABR5MW"
   },
   "source": [
    "<div>\n",
    "<img src=\"GoogleSearch.png\" width=\"500px\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5sUjQPWR5MW"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIBph0C8R5MX"
   },
   "source": [
    "## Language Models are used everywhere.\n",
    "## Today we will learn how we can use the concept of n-gram approxmiations & counting to create such models\n",
    "\n",
    "##\n",
    "\n",
    "## -> More to come: \"Language models II: RNN neural, write whole novels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjAa8IiKR5MX"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Udc7ulJdR5MX"
   },
   "source": [
    "## Find next word:\n",
    "\n",
    "## $P(\\text{word}|\\text{history}) = ?$\n",
    "\n",
    "##\n",
    "\n",
    "### $P(\\text{word}|\\text{\"I go to the beach to\"})$\n",
    "- ### run?\n",
    "- ### swim?\n",
    "- ### printer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTYiTVeKR5MY"
   },
   "source": [
    "## What is the naive solution here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66qh7necR5MY"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43vxaROOR5MY"
   },
   "source": [
    "## Compare probability of all possible sentence completions!\n",
    "\n",
    "### Counts(I go to the beach to *run*)\n",
    "### - vs\n",
    "### Counts(I go to the beach to *swim*)\n",
    "### - vs\n",
    "### Counts(I go to the beach to *printer*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw2rB2Q4R5MY"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARf3Y8fFR5MZ"
   },
   "source": [
    "## However..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_MmjNe_R5MZ"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1692N6HR5MZ"
   },
   "source": [
    "<div>\n",
    "<img src=\"Google2.png\" width=\"800px\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfh56SuQR5MZ"
   },
   "source": [
    "## Language is creative, so realistically we need to improve on basic counting.\n",
    "\n",
    "## How can we do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5BgaBKJR5MZ"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp46rLjTR5Ma"
   },
   "source": [
    "## -> N-gram approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPOvRJ3QR5Ma"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr30OLYhR5Ma"
   },
   "source": [
    "## Some notation\n",
    "\n",
    "- ### A sentence with n words $w_1, w_2, ..., w_n$ = $w_1^n$\n",
    "- ### Each word is a random variables over a vocabulary $w \\in vocab$ where $len(vocab) = V$\n",
    "\n",
    "### Chain rule of probability - Probability of sentence\n",
    "- ### $P(w_1^n) =P(w_1)P(w_2|w_1)P(w_3|w_1^2)...P(w_n|w_1^{n-1})=\\displaystyle\\prod_{k=1}^{n}P(w_k|w_1^{k-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nXNwr5MR5Ma"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3Jx2pVBR5Ma"
   },
   "source": [
    "## Simplest Approximation: independent unigrams\n",
    "### $P(w_k|w_1^{k-1})‚âàP(w_k)$\n",
    "### $P(w_k) = \\frac{C(w_k)}{\\sum C(w_j)} = \\frac{C(w_k)}{N}$ where $N$ is the number of words in a training corpus\n",
    "\n",
    "##\n",
    "\n",
    "### What is the next logical step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lY9mHMHJR5Mb"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hud2yC5R5Mb"
   },
   "source": [
    "## General Approximation: use history of up to N tokens for each estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzxzgszMR5Mb"
   },
   "source": [
    "### Note: This can be seen as a Markov model (limited history determins the probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbNRqEYzR5Mb"
   },
   "source": [
    "## eg: 2-gram model:\n",
    "### $P(w_k|w_1^{k-1})‚âàP(w_k|w_{k-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWoW6PR9R5Mc"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp1TmcQUR5Mc"
   },
   "source": [
    "## How do we estimate the probability of a word in a bigram model $ùëÉ(ùë§_ùëò|ùë§_{ùëò‚àí1})$?\n",
    "## Counts of bigram $w_{k-1}w_k$, divided by number of all bigrams starting with $w_{k-1}$\n",
    "\n",
    "## $ùëÉ(ùë§_ùëò|ùë§_{ùëò‚àí1})=\\frac{C(w_{k-1}w_k)}{\\sum_{w'}C(w_{k-1}w'_k)}$\n",
    "\n",
    "## Number of bigrams starting with $w_{k-1}$ simplifies to number of unigrams $w_{k-1}$\n",
    "\n",
    "## $ùëÉ(ùë§_ùëò|ùë§_{ùëò‚àí1})=\\frac{C(w_{k-1}w_k)}{C(w_{k-1})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_Xu8Z9qR5Mc"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-S2BIXZ1R5Mc"
   },
   "source": [
    "## Calculation Example - bigrams\n",
    "\n",
    "### Note: we want to keep track of beginning/end of sentences. Introduce `<s>` \\& `</s>`.\n",
    "\n",
    "### Train corpus:\n",
    "\n",
    "- ### \\<s\\> I am Sam \\</s\\>\n",
    "- ### \\<s\\> Sam I am \\</s\\>\n",
    "- ### \\<s\\> I do not like green eggs and ham \\</s\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvK6OGxkR5Mc"
   },
   "source": [
    "### $$P(\\text{I}|\\text{<s>})=\\frac{2}{3}=.67 \\hskip 2em P(\\text{Sam}|\\text{<s>})=\\frac{1}{3}=.33 \\hskip 2em P(\\text{am}|\\text{I})=\\frac{2}{3}=.67$$\n",
    "### $$P(\\text{</s>}|\\text{Sam})=\\frac{1}{2}=.50 \\hskip 2em P(\\text{Sam}|\\text{am})=\\frac{1}{2}=.50 \\hskip 2em P(\\text{do}|\\text{I})=\\frac{1}{3}=.33$$\n",
    "\n",
    "### $$P(\\text{\"I am Sam\"}) = P(\\text{I}|\\text{<s>}) ~ \\times ~ P(\\text{am}|\\text{I}) ~ \\times ~...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaMmJo8CR5Mc"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWuiFFTTR5Md"
   },
   "source": [
    "## Larger corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 851,
     "status": "error",
     "timestamp": 1727208905749,
     "user": {
      "displayName": "Andrew Zachary",
      "userId": "08217951406983746510"
     },
     "user_tz": 240
    },
    "id": "Xvr_L2d4R5Md",
    "outputId": "172df5df-8971-4310-9f47-2acea4427048"
   },
   "outputs": [],
   "source": [
    "# ignore this code for now, we will get back to it later\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "wiki_df = pd.read_csv('kdwd_r1k_articles.csv')\n",
    "def get_tokens(text):\n",
    "    return ['<s>'] + re.findall(r'\\w+', text.lower()) + ['</s>']\n",
    "sentences_list = ' '.join(wiki_df['intro_text'].tolist()).split('.')\n",
    "full_token_list = [get_tokens(text) for text in sentences_list]\n",
    "unigram_counts = Counter()\n",
    "for token_list in full_token_list:\n",
    "    for t in token_list:\n",
    "        unigram_counts[t] += 1\n",
    "bigram_counts = Counter()\n",
    "for token_list in full_token_list:\n",
    "    for t1, t2 in zip(token_list, token_list[1:]):\n",
    "        bigram_counts[t1 + ' ' + t2] += 1\n",
    "def get_mat(sentence, do_norm=False):\n",
    "    tokens = get_tokens(sentence)\n",
    "    mat_counts = np.zeros((len(tokens), len(tokens)))\n",
    "    for n1, t1 in enumerate(tokens):\n",
    "        for n2, t2 in enumerate(tokens):\n",
    "            if do_norm:\n",
    "                mat_counts[n1, n2] = bigram_counts[t1 + ' ' + t2] / unigram_counts[t1]\n",
    "                df = pd.DataFrame(mat_counts, index=tokens, columns=tokens).round(5)\n",
    "            else:\n",
    "                mat_counts[n1, n2] = int(bigram_counts[t1 + ' ' + t2])\n",
    "                df = pd.DataFrame(mat_counts, index=tokens, columns=tokens).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5BoIue1zTmjp"
   },
   "outputs": [],
   "source": [
    "def get_mat(sentence, do_norm=False):\n",
    "    tokens = get_tokens(sentence)\n",
    "    mat_counts = np.zeros((len(tokens), len(tokens)))\n",
    "    for n1, t1 in enumerate(tokens):\n",
    "        for n2, t2 in enumerate(tokens):\n",
    "            if do_norm:\n",
    "                mat_counts[n1, n2] = bigram_counts[t1 + ' ' + t2] / unigram_counts[t1]\n",
    "                df = pd.DataFrame(mat_counts, index=tokens, columns=tokens).round(5)\n",
    "            else:\n",
    "                mat_counts[n1, n2] = int(bigram_counts[t1 + ' ' + t2])\n",
    "                df = pd.DataFrame(mat_counts, index=tokens, columns=tokens).astype(int)\n",
    "    return df\n",
    "\n",
    "def get_tokens(text):\n",
    "    return ['<s>'] + re.findall(r'\\w+', text.lower()) + ['</s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "error",
     "timestamp": 1727118902401,
     "user": {
      "displayName": "Andrew Zachary",
      "userId": "08217951406983746510"
     },
     "user_tz": 240
    },
    "id": "ZdUv4q6XR5Md",
    "outputId": "2da310e5-8fd5-4a63-9b9f-235b682f771e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>wayfair</th>\n",
       "      <th>has</th>\n",
       "      <th>offices</th>\n",
       "      <th>throughout</th>\n",
       "      <th>the</th>\n",
       "      <th>united</th>\n",
       "      <th>states</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>918</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayfair</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offices</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughout</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>states</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            <s>  wayfair  has  offices  throughout  the  united  states  </s>\n",
       "<s>           0        2    5        1           2  918       9      10    13\n",
       "wayfair       0        0    1        0           0    0       0       0     0\n",
       "has           0        0    0       14           0    3       0       0     1\n",
       "offices       0        0    0        0           3    0       0       0     2\n",
       "throughout    0        0    0        0           0   37       0       0     0\n",
       "the           0        0    0        0           0    0     274       1     0\n",
       "united        0        0    0        0           0    0       0     393     0\n",
       "states        0        0    0        0           0    9       2       0   136\n",
       "</s>          0        0    0        0           0    0       0       0     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'wayfair has offices throughout the united states'\n",
    "get_mat(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T5lDi_X2R5Md",
    "outputId": "dff7b311-001c-40ef-9626-8e3ca134cf86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>wayfair</th>\n",
       "      <th>has</th>\n",
       "      <th>offices</th>\n",
       "      <th>throughout</th>\n",
       "      <th>the</th>\n",
       "      <th>united</th>\n",
       "      <th>states</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayfair</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offices</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughout</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>states</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            <s>  wayfair    has  offices  throughout    the  united  states  \\\n",
       "<s>         0.0      0.0  0.001    0.000       0.000  0.153   0.002   0.002   \n",
       "wayfair     0.0      0.0  0.250    0.000       0.000  0.000   0.000   0.000   \n",
       "has         0.0      0.0  0.000    0.038       0.000  0.008   0.000   0.000   \n",
       "offices     0.0      0.0  0.000    0.000       0.039  0.000   0.000   0.000   \n",
       "throughout  0.0      0.0  0.000    0.000       0.000  0.771   0.000   0.000   \n",
       "the         0.0      0.0  0.000    0.000       0.000  0.000   0.056   0.000   \n",
       "united      0.0      0.0  0.000    0.000       0.000  0.000   0.000   0.887   \n",
       "states      0.0      0.0  0.000    0.000       0.000  0.020   0.004   0.000   \n",
       "</s>        0.0      0.0  0.000    0.000       0.000  0.000   0.000   0.000   \n",
       "\n",
       "             </s>  \n",
       "<s>         0.002  \n",
       "wayfair     0.000  \n",
       "has         0.003  \n",
       "offices     0.026  \n",
       "throughout  0.000  \n",
       "the         0.000  \n",
       "united      0.000  \n",
       "states      0.302  \n",
       "</s>        0.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'wayfair has offices throughout the united states'\n",
    "get_mat(sentence, do_norm=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAtlnbawR5Me"
   },
   "source": [
    "### $$P(\\text{<s>} ~ \\text{wayfair has offices throughout the united states} ~ \\text{</s>})$$\n",
    "### $$= P(\\text{wayfair}|\\text{<s>}) \\times P(\\text{has}|\\text{wayfair}) \\times P(\\text{offices}|\\text{has}) \\times ~... $$\n",
    "### $$= 0.00033 \\times 0.25000 \\times 0.03763 \\times ~... $$\n",
    "### $$= 0.00000... $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_EYgJyrR5Me"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz-8iV-gR5Me"
   },
   "source": [
    "## Some of these probabilities quickly get very small -> use logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kTtnMEujR5Me",
    "outputId": "a020d3db-310f-4abc-f614-5f16378c4737"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(fontsize=16)\n",
    "plt.plot(np.arange(0,1,0.001)[1:], np.log(np.arange(0,1,0.001)[1:]))\n",
    "plt.xlabel('P')\n",
    "plt.ylabel('log(P)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH3Eh9HbR5Mf"
   },
   "source": [
    "- ## Convenient to deal with small numbers and multiplications become sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlnRgXnjR5Mf"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nubtbEG0R5Mf"
   },
   "source": [
    "## Before we build our first language model, how will we evaluate it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1vmz2bxR5Mf"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx7x6KRoR5Mf"
   },
   "source": [
    "## 1. Downstream task (extrinsic)\n",
    "\n",
    "### The best judge of a language model is its benefit in another task.\n",
    "\n",
    "### For example:\n",
    "\n",
    "- ### Does our translation output improve by using a language model?\n",
    "- ### Can we classify spam better by using a language model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXl1_1-kR5Mg"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9II8Cw7R5Mg"
   },
   "source": [
    "## 2. Perplexity (intrinsic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3aTUehkR5Mg"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZCKeS7AR5Mg"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6bkz0v1R5Mg"
   },
   "source": [
    "##  Definition: inverse probability of a test set\n",
    "### aka: Measure on how likely an unseen text is under a specific Language Model\n",
    "\n",
    "## $PP(W) = P(w_1...w_N)^{-\\frac{1}{N}}$\n",
    "\n",
    "- ### lower perplexity is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ie9txMLR5Mg"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCSI8YayR5Mg"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7U0xtU8R5Mh"
   },
   "source": [
    "## using chainrule we get\n",
    "\n",
    "### unigrams: $PP(W) = (\\displaystyle\\prod_{k=1}^{N}\\frac{1}{P(w_k)})^{\\frac{1}{N}}$\n",
    "\n",
    "### bigrams: $PP(W) = (\\displaystyle\\prod_{k=1}^{N}\\frac{1}{P(w_k|w_{k-1})})^{\\frac{1}{N}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJMDlsf3R5Mh"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c5J2v99R5Mh"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4j9HK4yR5Mh"
   },
   "source": [
    "### Pros:\n",
    "- #### simpler, doesn't need a task\n",
    "\n",
    "### Cons:\n",
    "- #### inapplicable to unnormalized language models (i.e., models that are not true probability distributions that sum to 1)\n",
    "- #### not comparable between language models with different vocabularies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3ItC_FNR5Mh"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRy9Hl5NR5Mh"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URGYJ7pfR5Mh"
   },
   "source": [
    "### we can use this as an 'unsupervised' proxy on how useful our model will be in a downstream task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQT1scpBR5Mh"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvhpVrGAR5Mh"
   },
   "source": [
    "#### [more reading] (optional) https://towardsdatascience.com/perplexity-in-language-models-87a196019a94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkI8CMO9R5Mi"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCzSE5r1R5Mi"
   },
   "source": [
    "## Building an n-gram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IsO0NGUZR5Mi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "wiki_df = pd.read_csv('kdwd_r1k_articles.csv')\n",
    "\n",
    "def get_tokens(text):\n",
    "    return ['<s>'] + re.findall(r'\\w+', text.lower()) + ['</s>']\n",
    "\n",
    "train_sentences_list = ' '.join(wiki_df['intro_text'].iloc[:-100].tolist()).split('.')\n",
    "test_sentences_list = ' '.join(wiki_df['intro_text'].iloc[-100:].tolist()).split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0xXGyNDCR5Mi"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_token_list = [get_tokens(text) for text in train_sentences_list]\n",
    "\n",
    "unigram_counts = Counter()\n",
    "for token_list in train_token_list:\n",
    "    for t in token_list:\n",
    "        unigram_counts[t] += 1\n",
    "\n",
    "bigram_counts = Counter()\n",
    "for token_list in train_token_list:\n",
    "    for t1, t2 in zip(token_list, token_list[1:]):\n",
    "        bigram_counts[t1 + ' ' + t2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0xpTQr91R5Mi",
    "outputId": "1877fc0c-9235-43ee-f70f-4b6fd1d6b0f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 5322),\n",
       " ('</s>', 5322),\n",
       " ('the', 4349),\n",
       " ('and', 3751),\n",
       " ('in', 3313),\n",
       " ('of', 2165),\n",
       " ('company', 1657),\n",
       " ('is', 1504),\n",
       " ('a', 1175),\n",
       " ('to', 960)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DYqFUv_YR5Mi",
    "outputId": "2e89d478-68b9-440b-b4b4-c787af10d21d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the company', 855),\n",
       " ('<s> the', 812),\n",
       " ('in the', 648),\n",
       " ('of the', 504),\n",
       " ('inc </s>', 394),\n",
       " ('<s> in', 378),\n",
       " ('is an', 374),\n",
       " ('<s> it', 369),\n",
       " ('united states', 350),\n",
       " ('an american', 345)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LFpbxppTR5Mj"
   },
   "outputs": [],
   "source": [
    "n_unigrams = np.sum([v for _, v in unigram_counts.items()])\n",
    "\n",
    "def get_unigram_token_prob(token):\n",
    "    return unigram_counts[token] / n_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_3ND-xWBR5Mj",
    "outputId": "17b6f352-6195-4860-97db-b1c1e667abc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04554355907886607"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unigram_token_prob('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "k93-mBeRR5Mj",
    "outputId": "9365ce49-c5f1-4650-9934-4dd21a43cd36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004607764082478977"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unigram_token_prob('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uO3Nqy8KR5Mj"
   },
   "outputs": [],
   "source": [
    "def get_text_prob_unigram(text):\n",
    "    tokens = get_tokens(text)\n",
    "    logp = 0\n",
    "    for t in tokens[1:-1]:\n",
    "        logp += np.log(get_unigram_token_prob(t))\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Nkb9HJaER5Mj",
    "outputId": "e7cc8664-ed43-4871-a73a-2c98be63df9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.125937335501064"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_unigram('apple inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "h0L5K_9SR5Mj",
    "outputId": "7201c83f-cab3-4ac8-8aa8-f3952af4639f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.125937335501064"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_unigram('inc apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5z9_nm9HR5Mj",
    "outputId": "c6c79000-0941-481a-9062-5bb5b060e200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.357625459234043"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_unigram('apple steve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NmhgMMFoR5Mk"
   },
   "outputs": [],
   "source": [
    "def get_bigram_token_prob(token1, token2):\n",
    "    return bigram_counts[token1 + ' ' + token2] / unigram_counts[token1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6-fJfE5MR5Mk"
   },
   "outputs": [],
   "source": [
    "def get_text_prob_bigram(text):\n",
    "    tokens = get_tokens(text)\n",
    "    logp = 0\n",
    "    for t1, t2 in zip(tokens[1:-1], tokens[2:]):\n",
    "        logp += np.log(get_bigram_token_prob(t1, t2))\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bKDpNlwYR5Mk",
    "outputId": "fb7a1380-71a0-4724-880f-8cc59f4b508a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.4449919564614695"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_bigram('apple inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TlvNpBBRR5Mk",
    "outputId": "d111d1b1-24b1-4962-9d13-81640b2ea49c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n7/btm17_wx4qbd75mnb8jvst6w0000gn/T/ipykernel_62993/1581132757.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logp += np.log(get_bigram_token_prob(t1, t2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_bigram('inc apple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHekuU4PR5Mk"
   },
   "source": [
    "## There is a problem that we have glossed over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jUysO5KgR5Mk",
    "outputId": "ad9f0e13-78ed-40b6-8b56-edb0f78e81fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n7/btm17_wx4qbd75mnb8jvst6w0000gn/T/ipykernel_62993/1322820601.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  logp += np.log(get_unigram_token_prob(t))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_unigram('dolphin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qIA_PmFR5Ml"
   },
   "source": [
    "## We get a probability of 0 for unknown unigrams! This will make all text have probability 0!\n",
    "## Same for bigrams, so even closed/giant vocabulary doesn't help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip6OmClgR5Ml"
   },
   "source": [
    "## How do we prevent this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHVxJCTnR5Ml"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O52wR65R5Ml"
   },
   "source": [
    "## Add count 1 to everything, keep normalized\n",
    "### This is also known as \"Laplace smoothing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "SNa6yVy5R5Ml"
   },
   "outputs": [],
   "source": [
    "def get_unigram_token_prob(token):\n",
    "    return (unigram_counts[token] + 1) / (n_unigrams + len(unigram_counts))\n",
    "\n",
    "def get_bigram_token_prob(token1, token2):\n",
    "    return (bigram_counts[token1 + ' ' + token2] + 1) / (unigram_counts[token1] + len(unigram_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nI8wEcR7R5Ml",
    "outputId": "ad40225c-28e7-4732-bc1d-d5dae6d70793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.174298600628918"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_bigram('dolphin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "x4-XMWEDR5Ml",
    "outputId": "d8176a47-475c-4888-dc56-6d614ff07d0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.353873731733426"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_prob_bigram('apple sky')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6KLJIROR5Ml"
   },
   "source": [
    "### evaluate perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tLY0Z5LR5Mm"
   },
   "source": [
    "#### reminder, for bigrams:\n",
    "$PP(W) = (\\displaystyle\\prod_{k=1}^{N}\\frac{1}{P(w_k|w_{k-1})})^{\\frac{1}{N}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8Qd5LX9PR5Mm"
   },
   "outputs": [],
   "source": [
    "def get_text_ppl_unigram(text):\n",
    "    tokens = get_tokens(text)\n",
    "    n_tokens = len(tokens)\n",
    "    logp = 0\n",
    "    for t in tokens[1:-1]:\n",
    "        logp += np.log(get_unigram_token_prob(t))\n",
    "    return (1 / np.exp(logp))**(1 / n_tokens)\n",
    "\n",
    "def get_text_ppl_bigram(text):\n",
    "    tokens = get_tokens(text)\n",
    "    n_tokens = len(tokens)\n",
    "    logp = 0\n",
    "    for t1, t2 in zip(tokens, tokens[1:-1]):\n",
    "        logp += np.log(get_bigram_token_prob(t1, t2))\n",
    "    return (1 / np.exp(logp))**(1 / n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8_IMeScR5Mn"
   },
   "source": [
    "### Let's look at a common phrase in our (small) training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IkYCY-GMR5Mn",
    "outputId": "ec90a094-3642-4717-9afc-2de08372554c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00025680778412927893"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unigram_token_prob('exploration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZcdCLzObR5Mn",
    "outputId": "d91aaa1c-5657-4fa1-f785-22ce017480a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011391880695940347"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bigram_token_prob('hydrocarbon', 'exploration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "P9E-JFVVR5Mn",
    "outputId": "7af611b1-e154-4045-b739-d047341d2692"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108.80734521775413"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_ppl_unigram('is a company engaged in hydrocarbon exploration.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ECBT8HXfR5Mo",
    "outputId": "90ada14d-6dd7-4929-8b79-62a7b0b4c20c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.31064151724841"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_ppl_bigram('is a company engaged in hydrocarbon exploration.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9yMUGk6R5Mo"
   },
   "source": [
    "### Not surprisingly our bigram model does better.\n",
    "\n",
    "### What if we look at our whole test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "EUtAXfpbR5Mo",
    "outputId": "b6741663-8967-4f0b-8e77-4f5e652c880b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604.5126361852824"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_list = []\n",
    "for text in test_sentences_list:\n",
    "    ppl_list.append(get_text_ppl_unigram(text))\n",
    "np.mean(ppl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "QsKmXARXR5Mo",
    "outputId": "fd682baa-dfe7-418c-dac9-393fd808c9e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892.5030633621313"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_list = []\n",
    "for text in test_sentences_list:\n",
    "    ppl_list.append(get_text_ppl_bigram(text))\n",
    "np.mean(ppl_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzhxgMCoR5Mo"
   },
   "source": [
    "## The bigram model perplexity for our test set is actually higher! (overfit)\n",
    "\n",
    "## -> Depending on train data size, vocabulary size, n-gram choice, the results here are a decent guideline, but nothing really substitues extrinsic (on-task) evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMz6BHn2R5Mo"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfpO4xA3R5Mo"
   },
   "source": [
    "## Example plots for large-scale datasets:\n",
    "\n",
    "![PerplexityFromGoog.png](attachment:image.png)\n",
    "\n",
    "<div style=\"text-align: right\"><small> [ref] deliprao.com/archives/201</small></div>\n",
    "    \n",
    "- ### more training data is better\n",
    "- ### higher ngram is better, usually up to a point (overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hafrSr2vR5Mo"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDqmuJq3R5Mo"
   },
   "source": [
    "![image.png](SOTANLP.png)\n",
    "<div style=\"text-align: right\"><small>[ref] paperswithcode</small></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KP3S4MfbR5Mo"
   },
   "source": [
    "- ## SOTA drastically improved over the past few years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6PAAKONR5Mo"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O9FniipR5Mo"
   },
   "source": [
    "## Returning to our problem of unknown word: P(unigram)=0\n",
    "\n",
    "## Adding +1 to every token was a simple way to prevent 0.\n",
    "\n",
    "##\n",
    "\n",
    "## How else can we handle unknown words in test?\n",
    "## or: How do we get a good estimate for how common they are?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "empVwBxYR5Mo"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVfRfi7bR5Mo"
   },
   "source": [
    "<div>\n",
    "<img src=\"UnknownWord1.png\" width=\"600px\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWVef0gvR5Mp"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obBxGqXkR5Mp"
   },
   "source": [
    "## Make dedicated Token \\<unk\\> for rare words in train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIoIYLb1R5Mp"
   },
   "source": [
    "<div>\n",
    "<img src=\"UnknownWord2.png\" width=\"600px\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnP79XSWR5Mp"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBWIFR8kR5Mp"
   },
   "source": [
    "## Is there something smarter we can do for unknown n-grams?\n",
    "\n",
    "## Eg: \"computer science\": P(bigram)=0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GEXump9R5Mp"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0ATs7j9R5Mp"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsBLUG0fR5Mp"
   },
   "source": [
    "## Backoff (see Homework)\n",
    "\n",
    "## Estimate bigram probability via unigram probability\n",
    "\n",
    "### eg bigram $P(w_k|w_{k-1})$ has count 0 so we approximate with unigram $P(w_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vAgE5OhR5Mp"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYcSOTFZR5Mp"
   },
   "source": [
    "## Public use of n-gram models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NS-r16KR5Mp"
   },
   "source": [
    "![image.png](GoogleNGram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiLkiypYR5Mp"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yJyyQBUR5Mp"
   },
   "source": [
    "## Kenlm - An integrated n-gram LM framework\n",
    "\n",
    "### `pip install https://github.com/kpu/kenlm/archive/master.zip`\n",
    "\n",
    "- ### easy building of model\n",
    "- ### advanced smoothing\n",
    "- ### fast, small memory footprint, optimized for querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "kyYPVdouR5Mp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /usr/local/bin/pip: bad interpreter: /usr/local/opt/python@3.11/bin/python3.11: no such file or directory\n",
      "Requirement already satisfied: kenlm in /Users/Andrew/Library/Caches/pypoetry/virtualenvs/ssml-mR-Cegl2-py3.11/lib/python3.11/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Install kenlm package\n",
    "!pip install kenlm\n",
    "import kenlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeQynONMR5Mp"
   },
   "source": [
    "### 4-gram model, 200k vocab - 11Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5wJC0hrDR5Mp"
   },
   "outputs": [],
   "source": [
    "# https://dl.fbaipublicfiles.com/wav2letter/lexicon_free/librispeech/models/lm/lm_librispeech_kenlm_word_4g_200kvocab.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "jdZLOSM7R5Mp"
   },
   "outputs": [],
   "source": [
    "model = kenlm.Model('lm_librispeech_kenlm_word_4g_200kvocab.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "-gKi9vOgR5Mp",
    "outputId": "c1c25e39-eb1a-4e2a-cc03-8ba3ce5984e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence score: -208.19174194335938 \n",
      "\n",
      "\n",
      "CPU times: user 543 Œºs, sys: 142 Œºs, total: 685 Œºs\n",
      "Wall time: 1.82 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentence = \"\"\"\n",
    "After adding nearly 27 million new paying subscribers in the first six months of 2020, Netflix warned investors to brace for a slowdown. Analysts expect only 3.8 million new paid subscribers for the third quarter when Netflix reports results Tuesday afternoon. That would mark its lowest quarterly pickup in more than a year\n",
    "\"\"\".lower()\n",
    "print(\"Sentence score:\", model.score(sentence), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xVg9aC8R5Mq"
   },
   "source": [
    "### Example: sentence likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "AlJ0VDukR5Mq",
    "outputId": "c691285d-f4d5-4562-e0cf-8fdf110fe19f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-33.94782638549805"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"ate yesterday burger at i a mit\"\n",
    "model.score(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2Ao50E0lR5Mq",
    "outputId": "59efc0b9-1ae7-4339-9862-de0e39640dbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.17040252685547"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"yesterday i ate a mit at burger\"\n",
    "model.score(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "_lyfdDDnR5Mq",
    "outputId": "e68553e5-6d65-4ae0-cc54-0ae61109dcdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.033166885375977"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"yesterday i ate a burger at mit\"\n",
    "model.score(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23.912525177001953"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I went to the beach to food\"\n",
    "model.score(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMA4_X80R5Mq"
   },
   "source": [
    "### Example: predict next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "i-ZPbEttR5Mq",
    "outputId": "fe133c3a-f2dd-45ae-902b-89aaafa44c84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.967015266418457"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"wet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "y8Oay4FAR5Mq",
    "outputId": "335f3d06-22d9-4476-9f44-1f3f064a3e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.306774616241455"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AF4XX_CWR5Mq"
   },
   "source": [
    "### `\"red\"` is more likely than `\"wet\"`\n",
    "\n",
    "### What if we try to complete the sentence: \"ocean water is\"\n",
    "### `\"wet\"` more likely than `\"red\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "oehIzbv5R5Mq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wet -14.039976119995117\n",
      "red -15.215217590332031\n",
      "desktop -19.074228286743164\n",
      "xyz... -20.774600982666016\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ocean water is\"\n",
    "for token in [\"wet\", \"red\", \"desktop\", \"xyz...\"]:\n",
    "    print(token, model.score(sentence + \" \" + token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "li1ip-gfR5Mq"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hukrYOvJR5Mq"
   },
   "source": [
    "## Optional continued reading\n",
    "\n",
    "- ### Kneser-Ney Smoothing\n",
    "    - #### http://smithamilli.com/blog/kneser-ney/\n",
    "\n",
    "- ### Kenlm\n",
    "    - #### https://kheafield.com/code/kenlm/\n",
    "    - #### https://www.aclweb.org/anthology/P13-2121.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fEeiVSWR5Mq"
   },
   "source": [
    "# $ \\\\ $\n",
    "# $ \\\\ $\n",
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmwO5j4-R5Mq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNozZe0sR5Mq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqVqn76AR5Mq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyLly0E2R5Mr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bnjN4OuR5Mr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byd5etKNR5Mr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vvEU9lxR5Mr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
