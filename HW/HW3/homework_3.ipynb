{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $ \\\\ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Obtain structured company data using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>page_views</th>\n",
       "      <th>intro_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>190485</td>\n",
       "      <td>Apple Inc. is an American multinational techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2386</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>40829</td>\n",
       "      <td>American Airlines, Inc. (AA) is a major Americ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id         page_title  page_views  \\\n",
       "0      856         Apple Inc.      190485   \n",
       "1     2386  American Airlines       40829   \n",
       "\n",
       "                                          intro_text  \n",
       "0  Apple Inc. is an American multinational techno...  \n",
       "1  American Airlines, Inc. (AA) is a major Americ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.read_csv('../../data/kdwd_r1k_articles.csv')\n",
    "wiki_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Write a regex to find unusually capitalized terms\n",
    "Sometimes product names will have unusual capitalization such as iPhone or ThinkPad. Find a list of such terms and investigate if you think some of them are products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_products_ptn = r'' # find the correct regular expression here\n",
    "\n",
    "\n",
    "# code here!\n",
    "\n",
    "\n",
    "# print(len(maybe_products_set), 'terms found that are potential products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that we found some of the key terms\n",
    "assert('iPhone' in maybe_products_set)\n",
    "assert('ThinkPad' in maybe_products_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Parse company acquisition data from plain text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking to identify the following types of patterns.<br />\n",
    "`'Citrix acquired Sequoia Software Corp'`<br />\n",
    "`'Moody\\'s was acquired by Dun & Bradstreet in 1962.'`<br />\n",
    "The idea here is to look for patterns around the word 'acquire' with two valid entities on either side, and an option year at the end.<br />\n",
    "<span style=\"color:orange\">Helpful Reminder:</span> you can create non-capturing capture groups via `(?:capture this|or that)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a way to capture, 'FedEx', 'Coca-Cola', 'Sequoia Software Corp', 'Dun & Bradstreet' and 'Moody\\'s'\n",
    "company_ptn = r''  # write pattern\n",
    "\n",
    "\n",
    "# code here!\n",
    "\n",
    "\n",
    "# print(len(maybe_companies_set), 'terms found that are potential companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that we found some of the key terms\n",
    "assert('FedEx' in maybe_companies_set)\n",
    "assert('Coca-Cola' in maybe_companies_set)\n",
    "assert('Sequoia Software Corp' in maybe_companies_set)\n",
    "assert('Dun & Bradstreet' in maybe_companies_set)\n",
    "assert('Moody\\'s' in maybe_companies_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquisition pattern\n",
    "acquisition_ptn = r'(?:acquired|was acquired by)'\n",
    "\n",
    "# find a way to optionally capture the year such as ' in 1962'\n",
    "optional_year_ptn = r'(?: in [12][0-9]{3}\\b)?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's assemble the patterns together to a full capture pattern\n",
    "full_acquisition_pattern = (\n",
    "    company_ptn + r'\\s+' + acquisition_ptn + r'\\s+' + company_ptn + optional_year_ptn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 potential acquisitions found.\n"
     ]
    }
   ],
   "source": [
    "acquisition_strings = []\n",
    "for _, row in wiki_df.iterrows():\n",
    "    acquisition_strings.extend(re.findall(full_acquisition_pattern, row['intro_text']))\n",
    "print(len(acquisition_strings), 'potential acquisitions found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that we found some of the key terms\n",
    "assert('Citrix acquired Sequoia Software Corp' in acquisition_strings)\n",
    "assert('Moody\\'s was acquired by Dun & Bradstreet in 1962' in acquisition_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Question: Are there any false positives in your results? If so, how could you account for them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Let's look into speed of regex matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a simple pattern of your choice to search for in our dataset\n",
    "search_ptn = r'iPhone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble a list of strings\n",
    "doc_list = wiki_df['intro_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 14.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# evaluation loop here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compile the regex and see if this increases the speed using `re.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787 µs ± 5.05 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# evaluation loop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on speed: basic string operations are always faster than regex\n",
    "#### show this using `'my_string' in 'other_string'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Word phrases\n",
    "\n",
    "### In this problem we will look at methods to identify valid n-grams such as 'New York' or 'Barack Obama' while eliminating statistical flukes such as `in the` or `i write`.\n",
    "\n",
    "### Preprocessing such as this can drastically improved embeddings since words can ngrams will often have a different meaning than the sum of its parts\n",
    "### `V('united')` + `V('states')` != `V('united states')`\n",
    "### `V('real')` + `V('estate')` != `V('real estate')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = pd.read_csv('../../data/kdwd_r1k_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get consecutive unigrams for the 'intro_text' column of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists of unigrams\n",
    "unigram_pattern = ...\n",
    "corpus = [re.findall(unigram_pattern, doc.lower()) for doc in wiki_df['intro_text'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The package `gensim` has a convenient wrapper to obtain statistically significant ngrams/Phrase automatically\n",
    "\n",
    "### we need to first `pip install gensim`\n",
    "### `gensim` is a useful library for anything related to word representations and embeddings. It will come up a few more times. https://radimrehurek.com/gensim/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write some code to parse our corpus and use valid ngrams using `Phrases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count_dict = {k: v for k, v in phrases.vocab.items()}\n",
    "\n",
    "n_grams = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_grams.shape[0], 'n-grams found')\n",
    "n_grams.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the results look? Can you improve the results by excluding common terms using the `connector_words` kwarg of `Phrases`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_grams.shape[0], 'n-grams found')\n",
    "n_grams.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This was convenient, but it's also a black box where many of the knobs for tuning are actually broken in the newest version. Let's try to create our own solution for finding n-grams.\n",
    "\n",
    "### To do this, let's start by counting unigrams and bigrams within our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip: use Counter for easy counting. It behaves similar to a dictionary with some added functionality around counting. such as `my_counter[unknown_key]` returning `0` for all unknown keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "unigram_counter = Counter()\n",
    "bigram_counter = Counter()\n",
    "for tokens in corpus:\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to come up with a score for each bigram that helps us decide on its importance and the fact of whether it is truly a bigram or two independent unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "bigram_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find ways to sort and filter your output to bigrams that make sense, such as `wells fargo`, `apple inc` or `puerto rico`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "filtered_bigram_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bigram_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Corporate Similarity and Returns\n",
    "### In this example we'll explore how to use NLP to measure corporate similarity\n",
    "\n",
    "### In particular we will\n",
    " - ### Make word vectors for firms in order to get an NLP measure of similarity\n",
    " - ### Measure the quality of this similarity metric by predicting future co-movement of returns. \n",
    " \n",
    "## Step X: This problem uses a few concepts of basic modeling such as `sklearn.model_selection.train_test_split` and `sklearn.linear_model.LinearRegression`\n",
    " \n",
    "\n",
    "# $ \\\\ $\n",
    "## Step 0: Load the MD&A section from Form-10-K from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/parsed_mda.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, take only the first filing for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "seen = set()\n",
    "for item in data:\n",
    "    if item['ticker'] in seen:\n",
    "        continue\n",
    "    else:\n",
    "        seen.add(item['ticker'])\n",
    "        clean.append(item)\n",
    "data = clean\n",
    "del clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load the price data for 2015-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\n",
    "    '../../data/sp500_prices.csv', \n",
    "    index_col=0, \n",
    "    parse_dates=True\n",
    ").loc['2015-01-01':'2018-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tickers = [item['ticker'] for item in data]\n",
    "assert len(data_tickers) == len(set(data_tickers)), 'non-unique tickers, this will not work'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: clean the text\n",
    "### Much of NLP boils down to doing reasonable processing on text.\n",
    "### First, we'll try out very minimial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mda_simple(mda):\n",
    "    return mda.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pairwise Word similarity\n",
    "### Calculate the pariwise cosine similarity between word vectors\n",
    "### Make the cosine similarities into a dataframe indexed/columned on ticker symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sims = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Why `cosine_similarity` and not another measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wrangle the price and word data\n",
    "### Our goal here is to have a dataframe which is indexed on PAIRS of tickers and has columns\n",
    " - ### `returns_correlation`: the correlation of returns for those two tickers from Jan 1 2016 to Jan 1 2017\n",
    " - ### `word_similarity`: the cosine similarity of the word vectors for the two companies' MD&A sections\n",
    " \n",
    "## Tips\n",
    " - ### NB: use pct_change to calculate returns in pandas\n",
    " - ### NB: use the pandas builtin corr function to calculate correlations (we don't need anything fancy)\n",
    " - ### NB: the index of the dataframe should have two columns (the tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way you might do this is\n",
    "rets_cor = ... # calculate returns correlations\n",
    "word_cor = #  calcuate the word similarities in the right shape\n",
    "\n",
    "all_data = rets_cor.join(word_cor)\n",
    "all_data = all_data.dropna()\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3a: \n",
    " - ### What is the contemperaneous correlation of these data?\n",
    " - ### Make a scatter plot of the returns correlation and word similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This should be about 12%. That's not bad, but we can do better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.plot.scatter(x='returns_correlation', y='word_similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Try to predict the future returns correlations\n",
    "### Use OLS (`LinearRegression`) to predict `returns_correlation` from `word_similarity`. \n",
    "### What is the (contemperaneous) out of sample performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df =  ...\n",
    "feature_cols =  ...\n",
    "target_col =  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here\n",
    "\n",
    "reg = ...# add code here\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(reg.coef_, index=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not amazing. We can do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ \\\\ $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Repeat, but be careful\n",
    "### Here we will see if we can clean the data better\n",
    "\n",
    "### Things to try\n",
    " - ### Look at the histograms of word similarities to see if we can \"ignore\" some ill-behaved data\n",
    " - ### Try limiting how greedy the `TFIDFVectorizer` is: `min_df`, `max_df`, `max_features`, etc.\n",
    " \n",
    "### We will examine our data and look for things that look out of place\n",
    " - ### We will ultimately want our data to look normally distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mda(mda):\n",
    "    paras = [p.lower() for p in mda.split('\\n') if len(p) > 40]\n",
    "    cleaned =  ' '.join(paras)\n",
    "    words = cleaned.split()\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    if len(words) > 10:\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(\n",
    "    min_df=...\n",
    "    max_df= ...\n",
    "    max_features= ...\n",
    ")\n",
    "word_vecs = vec.fit_transform((clean_mda(item['mda']) for item in data))\n",
    "\n",
    "\n",
    "word_sims =  ...\n",
    "# Lots of word similarities are all zeros- so we'll ignore\n",
    "# add code here to remove rows of word_sims where all the elements are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the returns correlation and the cosine similarities as above\n",
    "all_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect your data- make some histograms\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.returns_correlation.hist(bins=40)\n",
    "plt.title('Returns Correlation')\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.word_similarity.hist(bins=40)\n",
    "plt.title('Word Similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning our data\n",
    "### It seems lots of things are identically 0 (no word overlap) or identically 1 (the MD&A section for one company perfectly overlaps itself). We will exclude those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine histograms again\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.returns_correlation.hist(bins=40)\n",
    "plt.title('Returns Correlation')\n",
    "plt.figure(figsize=(12,7))\n",
    "all_data.word_similarity.hist(bins=40)\n",
    "plt.title('Word Similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, there is a bit of a \"hump\" at low `word_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here\n",
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The contemperaneous correlation is twice as large!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Now, repeat the exercise of predicting future returns correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df =  ...# Add code here\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg =  ...\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(reg.coef_, index=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is about 5 times better than before!\n",
    "## $ \\\\ $ \n",
    "## Part 7: What will happen if we include last year's returns correlation as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_year_corr =  ...\n",
    "data_df = last_year_corr.join( ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg =  ...\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(reg.coef_, index=feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indeed, we do much better, but the word features still help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
